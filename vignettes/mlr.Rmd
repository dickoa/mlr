---
title: "mlr: Machine Learning in R"
author: "Bernd Bischl, Michael Lang, Jakob Richter, Erich Studerus"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mlr}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

This Vignette is supposed to give you a short introductory glance at the key features of `mlr`.
A more detailed in depth and continuously updated tutorial can be found on the GitHub project page:
- [Project Page](https://github.com/berndbischl/mlr/)
- [Online Tutorial](http://berndbischl.github.io/mlr/tutorial/html/)
- [Download](http://berndbischl.github.io/mlr/tutorial/mlr_tutorial.zip) online tutorial as zip for offline usage

## Purpose

The main goal of `mlr` is to provide a unified interface for *machine learning tasks* as *classification*, *regression*, *cluster analysis* and *survival analysis* in R.
In lack of a common interface it becomes a hassle to carry out standard methods like cross validation and hyperparameter tuning for different learners.
Hence, `mlr` offers a simple and consistent way to

* train a learner and predict outcomes,
* modify hyperparameters of a learner,
* perform resampling and measure the performance, or
* tune the hyperparameters of a learner.


## Quick Start

To highlight the main principle of `mlr` we give a quick introduction to the package.
We demonstrate how to simply perform a classification analysis using a stratified cross validation which illustrates some of the major building blocks of the `mlr` workflow, namely tasks and learners.

```{r}
library(mlr)
data(iris)

## Define the task:
task = makeClassifTask(id = "tutorial", data = iris, target = "Species")
print(task)

## Define the learner:
lrn = makeLearner("classif.lda")
print(lrn)

## Define the resampling strategy:
rdesc = makeResampleDesc(method = "CV", stratify = TRUE)

## Do the resampling:
r = resample(learner = lrn, task = task, resampling = rdesc)
print(r)

## Get the mean misclassification error:
r$aggr
```

## Detailed Tutorial

The previous example just demonstrated a tiny fraction of the capabilities of `mlr`.
More features are covered in the tutorial which can be found online on the `mlr` project page.
It covers among others: *benchmarking*, *preprocessing*, *imputation*, *feature selection*, *ROC analysis*, how to implement your own learner and the list of all supported learners.
Reading is highly recommended!

* [Project Page](https://github.com/berndbischl/mlr/)
* [Online Tutorial](http://berndbischl.github.io/mlr/tutorial/html/)
* [Download](http://berndbischl.github.io/mlr/tutorial/mlr_tutorial.zip) online tutorial as zip for offline usage
* [Wiki](https://github.com/berndbischl/mlr/wiki) with additional information for developers


## Thanks

We would like to thank the authors of all packages `mlr` uses under the hood:

```{r,echo=FALSE,results="asis"}
parse_pkgs = function(x) {
  x = strsplit(x, "\n")[[1L]]
  x = sub("^([[:alnum:]]+).*", "\\1", x)
  x[nzchar(x)]
}

desc = read.dcf("../DESCRIPTION")
pkgs = c(parse_pkgs(desc[, "Depends"]), parse_pkgs(desc[, "Imports"]), parse_pkgs(desc[, "Suggests"]))
pkgs = sort(setdiff(pkgs, "R"))
cat(sprintf("* [%1$s](http://cran.r-project.org/web/packages/%1$s/)", pkgs), sep = "\n")
```
